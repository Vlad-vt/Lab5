# Lab5
SOA Lab5

------------------------------------1. Основні алгоритми квотування частоти запитів. Їх переваги та недоліки.------------------------------------

Leaky Bucket - це алгоритм, який забезпечує найпростіший, інтуїтивно зрозумілий підхід до обмеження швидкості обробки за допомогою черги, яку можна подати у вигляді «відра», що містить запити. Коли запит отримано, він додається до кінця черги. Через рівні проміжки часу перший елемент черги обробляється. Це також відоме як черга FIFO. Якщо черга заповнена, то додаткові запити відкидаються (або "витікають"). Перевага даного алгоритму полягає в тому, що він згладжує сплески та обробляє запити приблизно з однією швидкістю, його легко впровадити на одному сервері або балансувальнику навантаження, він ефективний використання пам'яті, так як розмір черги для кожного користувача обмежений. Однак при різкому збільшенні трафіку черга може заповнитися старими запитами та позбавити систему можливості обробляти свіжіші запити. Також він не дає гарантії, що запити будуть опрацьовані за якийсь фіксований час. Крім того, якщо для забезпечення відмовостійкості або збільшення пропускної спроможності ви завантажуєте балансувальники, то ви повинні реалізувати політику координації та забезпечення глобального обмеження між ними.
Fixed Window - алгоритм фіксованого вікна. У цьому алгоритмі для відстеження запитів використовується вікно n секундам. Зазвичай використовуються значення на зразок 60 секунд (хвилина) або 3600 секунд (година). Кожен вхідний запит збільшує лічильник цього вікна. Якщо лічильник перевищує якесь граничне значення, запит відкидається. Зазвичай вікно визначається нижньою межею поточного інтервалу, тобто при ширині вікна в 60 секунд, запит, що прийшов о 12:00:03, потрапить у вікно 12:00:00. Перевага цього алгоритму полягає в тому, що він забезпечує обробку свіжіших запитів, не зависаючи на обробці старих. Однак одиночний сплеск трафіку поблизу межі вікна може призвести до подвоєння кількості оброблених запитів, оскільки він дозволяє запити як для поточного, так і наступного вікна протягом короткого проміжку часу. Крім того, якщо багато користувачів чекають на скидання лічильника вікна, наприклад, в кінці години, вони можуть спровокувати зростання навантаження в цей момент через те, що звернуться до API одночасно.
Sliding Log - ковзний журнал. Даний алгоритм передбачає відстеження тимчасових позначок кожного запиту користувача. Ці записи зберігаються, наприклад, у hash set або таблицю та сортуються за часом; записи поза відстежуваного інтервалу відкидаються. Коли надходить новий запит, обчислюємо кількість записів, щоб визначити частоту запитів. Якщо запит виходить за рамки допустимої кількості, він відкидається. Перевага цього алгоритму в тому, що він не схильний до проблем, які виникають на межах Fixed Window, тобто обмеження швидкості буде суворо дотримуватися. Крім того, оскільки відстежуються запити кожного клієнта окремо, не виникає пікового зростання навантаження у певні моменти, що є ще однією проблемою попереднього алгоритму. Однак зберігати інформацію про кожен запит може бути дорого, крім того, кожен запит вимагає обчислення кількості попередніх запитів, потенційно на всьому кластері, внаслідок чого цей підхід погано масштабується для обробки великих сплесків трафіку та атак типу Denial of Service.
Sliding Window - ковзне вікно. Це гібридний підхід, який поєднує в собі низьку вартість обробки Fixed Window та покращену обробку граничних ситуацій Sliding Log. Як і в простому Fixed Window, ми відстежуємо лічильник для кожного вікна, а потім враховуємо зважене значення частоти запитів попереднього вікна на основі поточної мітки, щоб згладити сплески трафіку. Цей алгоритм дозволяє масштабувати rate limiting, зберігаючи хорошу продуктивність. Крім того, це зрозумілий спосіб донести клієнтам інформацію про обмеження кількості запитів, а також дозволяє уникнути проблем, що виникають під час реалізації інших алгоритмів rate limiting. 

------------------------------------2. Які переваги забезпечує квотування частоти запитів. Для яких сервісів є доцільним?------------------------------------

Обмеження швидкості зазвичай встановлюється як захисний захід для послуг. Спільні служби повинні захищатися від надмірного використання — навмисного чи ненавмисного — для підтримки доступності послуг. Навіть високомасштабовані системи повинні мати певні обмеження на споживання. Щоб система працювала добре, клієнти також повинні бути розроблені з урахуванням обмеження швидкості, щоб зменшити ймовірність каскадних збоїв . Обмеження швидкості як на стороні клієнта, так і на стороні сервера має вирішальне значення для максимізації пропускної здатності та мінімізації наскрізної затримки у великих розподілених системах.
Коли потужність служби розподіляється між багатьма користувачами або споживачами, вона може застосовувати обмеження швидкості для кожного користувача, щоб забезпечити чесне та розумне використання, не впливаючи на інших користувачів. Ці обмеження можуть застосовуватися протягом більш тривалих періодів часу або вони можуть застосовуватися до ресурсів, які вимірюються не швидкістю, а розподіленою кількістю. Ці ставки та обмеження розподілу разом називаються квотами . Квоти також можуть застосовуватися до пакетів монетизації API або безкоштовних обмежень рівня. Ви можете використовувати обмеження швидкості, щоб контролювати витрати⁠, наприклад, якщо основний ресурс може автоматично масштабуватися для задоволення попиту, але бюджет для використання цього ресурсу обмежений. Організація може використовувати обмеження ставок, щоб запобігти виходу експериментів з-під контролю та накопиченню великих рахунків. Частково це занепокоєння пояснюється тим, чому для багатьох квот Google Cloud встановлено початкові значення, які можна збільшити за запитом . Організації, які пропонують рішення SaaS (програмне забезпечення як послуга) з фіксованою вартістю, можуть застосовувати інші обмеження тарифів, які потребують моделювання вартості, ціни та маржі на кожного клієнта.

------------------------------------3. Квотування та горизонтальне масштабування клієнта.------------------------------------

Подібно до того, як основною метою служби при використанні обмеження швидкості є захист і підтримка доступності, основною метою клієнта є виконання запиту, який він робить до служби. У відповідь на помилки, що обмежують швидкість, періодичні чи неспецифічні помилки, клієнт зазвичай має повторити запит після затримки. Рекомендовано експоненціально збільшувати цю затримку після кожного невдалого запиту, що називається експоненціальним відстрочкою . Коли багато клієнтів можуть робити запити на основі розкладу (наприклад, отримання результатів щогодини), додатковий випадковий час ( тремтіння ) слід застосувати до часу запиту, періоду відстрочки або обох, щоб гарантувати, що ці кілька екземплярів клієнта не стануть періодично гримить стадо , і самі викликають форму DDoS.
Компанії, як правило, мають кілька екземплярів своїх програм, що працюють у хмарі одночасно. У міру масштабування стає важче гарантувати, що клієнтські запити щоразу отримуватимуть один екземпляр. Це робить горизонтальне масштабування з урахуванням стану (масштабування, яке передбачає зберігання даних між сеансами для подальшого використання) непридатним для більшості бізнес-додатків. З іншого боку, горизонтальне масштабування без збереження стану ідеально підходить для компаній, оскільки воно зосереджується на додатку, а не на інфраструктурі. Хмарні програми без збереження стану не взаємодіють постійно між запитами. Взаємодія між двома запитами, також відома як «сеанс», не зберігається в пам’яті програми. Програми без стану не зберігають дані минулого сеансу для використання в наступних сесіях. По суті, кожен сеанс запускається «вперше». Коли служба покладається на відстеження на стороні сервера, сеанси обов’язково прив’язуються до конкретних серверів. Переходячи без стану, тобто переміщуючи всі специфічні для сеансу дані на сторону клієнта, сеанси можуть безперешкодно оброблятися на всіх серверах. Це робить процес горизонтального масштабування просто прогулянкою по парку. Крім того, коли сотні, тисячі або навіть мільйони користувачів запускають окремі сеанси, масштабованість без збереження стану призведе до того, що ці сеанси працюватимуть взаємозамінно на всіх ваших серверах.
